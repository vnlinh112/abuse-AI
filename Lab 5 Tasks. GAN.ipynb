{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 5 Tasks. GAN","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN87TlN3U4QMtzvUdVcSMJl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BzICh99V8jOn","colab_type":"text"},"source":["**FIT3183 Malicious AI & Dark Side Security**\n","# Lab 5: Generative Adversarial Network\n","\n","There are 2 tasks:\n","* Implement your first GAN: Handwritten digits generator \n","* Synthesize face images with DCGAN\n","\n","ðŸ‘‰ ***Copy this Colab notebook to your Drive***, read the instruction and fill the missing code.\n","\n","ðŸ‘‰ ***Use GPU:*** `Runtime > Change runtime type > GPU`.\n","\n","*Note: If you are new to Google Colab and Pytorch: please read this [Pre-lab Activities](https://drive.google.com/file/d/1aBOkxvGxkOeZlZxYQy0xiEzdEwU-C1DX/view?usp=sharing) first.*\n","\n","<small>*Prepared by [Linh Vu](mailto:linh.vu@monash.edu) (Lab Tutor) Aug 2020.*"]},{"cell_type":"markdown","metadata":{"id":"4Vk8ljypdCD4","colab_type":"text"},"source":["## Task 1: Implement your first GAN - Handwritten digits generator \n","\n","Generative adversarial networks are machine learning systems that can learn to mimic a given distribution of data. GANs consist of two neural networks:\n","\n","* Generator, which is trained to generate data by learning the distribution of the training set;\n","* Discriminator, which is trained to distinguish fake data from real data.\n","\n","In this task, we are going to implement a simple GAN to generate images of handwritten digits with the MNIST dataset of handwritten digits with Pytorch.\n","\n","There are 3 subtasks:\n","* Implement the Discriminator\n","* Implement the Generator\n","* Training the models"]},{"cell_type":"markdown","metadata":{"id":"hBZgMrPgBjLD","colab_type":"text"},"source":["<img src=\"http://limg.surge.sh/gan_mnist.jpg\" width=600>"]},{"cell_type":"markdown","metadata":{"id":"CiYrKCvLcW3d","colab_type":"text"},"source":["### Initialization\n","\n","First, we setup environment & prepapre data."]},{"cell_type":"code","metadata":{"id":"valtgXGYKBl6","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","\n","import matplotlib.pyplot as plt\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import numpy as np\n","from matplotlib import rcParams\n","rcParams[\"savefig.jpeg_quality\"] = 50\n","import imageio\n","from pathlib import Path\n","# we don't like warnings\n","# you can comment the following 2 lines if you'd like to\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Set up a random generator seed so that the experiment can be replicated identically on any machine\n","torch.manual_seed(111)\n","\n","# Create a device object that points to the CPU or GPU if available\n","device = \"\"\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")\n","\n","# Define the transform to load grayscale images from MNIST dataset\n","# Note that grayscale images have only one channel\n","transform = transforms.Compose([transforms.ToTensor(), \n","                                transforms.Normalize((0.5,), (0.5,))\n","                                ])\n","\n","# Load MNIST dataset\n","train_set = torchvision.datasets.MNIST(\n","  root=\".\", train=True, download=True, transform=transform\n",")\n","\n","# Create a data loader to shuffle the data from train_set and return \n","# batches of 32 samples used for networks training\n","batch_size = 32\n","train_loader = torch.utils.data.DataLoader(\n","  train_set, batch_size=batch_size, shuffle=True, drop_last=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"efI5Mzx6QDjA","colab_type":"text"},"source":["The MNIST dataset consists of 28 Ã— 28 pixel grayscale images of handwritten digits from 0 to 9. Let's visualize the data to see. Since GANs make use of unsupervised learning techniques, we don't need to care about the label."]},{"cell_type":"code","metadata":{"id":"bhciamnZKLn_","colab_type":"code","colab":{}},"source":["real_samples, mnist_labels = next(iter(train_loader))\n","for i in range(16):\n","  ax = plt.subplot(4, 4, i + 1)\n","  plt.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n","  plt.xticks([])\n","  plt.yticks([])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CnA3EjRWwZiH","colab_type":"text"},"source":["The MNIST dataset consists of digits with different handwriting styles. As the GAN learns the distribution of the data, it will also generate digits with different handwriting styles.\n","\n","Now let's implement the discriminator and generator models."]},{"cell_type":"markdown","metadata":{"id":"ijMmLoDOihe4","colab_type":"text"},"source":["### Subtask 1.1: Implement the Discriminator\n","\n","The discriminator is model that receives a 28 Ã— 28 pixel image from the real data or from the generator and provides the probability of the image belonging to the real training data. \n","\n","***> What is the number of neuron for the input layer and output layer?***\n","\n","**Task: Implement the discriminator, which is a MLP model with:**\n","\n","* Input layer: `__` neurons (to process the image vector)\n","* 1st hidden layer: 1024 neurons, activation: ReLU, dropout (to avoid overfitting): 0.3\n","* 2nd hidden layer: 512 neurons, activation: ReLU, dropout: 0.3\n","* 3rd hidden layer: 256 neurons, activation: ReLU, dropout: 0.3\n","* Output layer: `__` neurons, activation: Sigmoid (to return the probability in range `[0, 1]`)"]},{"cell_type":"code","metadata":{"id":"GyxWeTOaKOaV","colab_type":"code","colab":{}},"source":["# Create class for the discriminator model that inherit from nn.Module\n","\n","class Discriminator(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.model = nn.Sequential(\n","      ## YOUR CODE HERE ##\n","      # Input layer: __ neurons. 1st hidden layer: 1024 neurons, activation: ReLU, dropout: 0.3 (3 lines)\n","      # nn.Linear(__ , 1024),\n","      # nn.ReLU(),\n","      # nn.Dropout(0.3),\n","      \n","      # 2nd hidden layer: 512 neurons, activation: ReLU, dropout: 0.3 (3 lines)\n","\n","\n","      # 3rd hidden layer: 256 neurons, activation: ReLU, dropout: 0.3 (3 lines)\n","\n","\n","      # Output layer: __ neurons, activation: Sigmoid (2 lines)\n","\n","\n","      ## END YOUR CODE HERE ##\n","    )\n","\n","  def forward(self, x):\n","    \"\"\"\n","    Input: \n","      x: tensor of images with shape: batch_size x channel x width x height (32 x 1 x 28 x 28)\n","    Return: \n","      output: the probability of x belong to the real training data, shape: batch_size x 1 (32 x 1)\n","    \"\"\"\n","    # Change x shape to: batch_size x dimension_of_input_layer (32 x 784)\n","    x = x.view(x.size(0), 784)\n","\n","    # Feed x to the model to predict the probability\n","    output = self.model(x)\n","\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"im_4KEVhKP25","colab_type":"code","colab":{}},"source":["# Create a Discriminator object and send it to GPU if available\n","discriminator = Discriminator().to(device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aloBfqO3Ac0M","colab_type":"text"},"source":["### Subtask 1.2: Implement the Generator\n","\n","In GANs, the generator takes samples from a latent space as its input and generates data resembling the data in the training set. In this case, the generator is going to be fed a 100-dimensional input, which is sufficient to generate images of handwritten digits. Then, it will provide an output with `__` coefficients, which will be organized in a 28 Ã— 28 tensor representing an image.\n","\n","The implementation is similar to what you did for the discriminator.\n","\n","***> What is the number of neuron for the input layer and output layer?***\n","\n","**Task: Implement the generator:**\n","* Define the neural network architectures in `__init__` function:\n","  * Input layer: `__` neurons (to process the latent vectors)\n","  * 1st hidden layer: 256 neurons, activation: ReLU\n","  * 2nd hidden layer: 512 neurons, activation: ReLU\n","  * 3rd hidden layer: 1024 neurons, activation: ReLU\n","  * Output layer: `__` neurons, activation: Tanh (to return the vector of coefficients with values in range `[-1, 1]` to generate image)\n","* Describe the training process in `forward` function:\n","  * Feed x to the model to generate vectors\n","  * Change the output shape to get the tensor of images\n","* Create a Generator object and send it to GPU if available"]},{"cell_type":"code","metadata":{"id":"QhNcqt-hKRio","colab_type":"code","colab":{}},"source":["# Create class for the generator model that inherit from nn.Module\n","\n","class Generator(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    ## YOUR CODE HERE ##\n","    # Define the neural network architectures\n","    # self.model = nn.Sequential(\n","    #   ...\n","    # )\n","    ## END YOUR CODE HERE ##\n","\n","  def forward(self, x):\n","    \"\"\"\n","    Input: \n","      x: tensor of latent vectors with shape: batch_size x dimension_of_latent_vector (32 x 100)\n","    Return: \n","      output: tensor of generated images with shape: batch_size x channel x width x height (32 x 1 x 28 x 28)\n","    \"\"\"\n","    ## YOUR CODE HERE ##\n","    # Feed x to the model to generate vectors (1 line)\n","    \n","    # Change the output shape to get the tensor of images (1 line)\n","    \n","    ## END YOUR CODE HERE ##\n","\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8RbssMbW9mA","colab_type":"code","colab":{}},"source":["## YOUR CODE HERE ##\n","# Create a Generator object and send it to GPU if available (1 line)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gFS6j8zCt3qM"},"source":["### Prepare for training\n","\n","Before training the models, we set up some parameters to use during training: learning rate, loss function, optimization algorithm, as well as define some helper classes to support visualization.\n","\n","Set up parameters for training process:"]},{"cell_type":"code","metadata":{"id":"iGYNBNz5KZbh","colab_type":"code","colab":{}},"source":["# learning rate: used to adapt the network weights\n","lr = 0.0001\n","# loss function: binary cross-entropy\n","loss_function = nn.BCELoss()\n","# create the optimizers using Adam algorithm for both models\n","optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n","optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u8pyo4MTvfBB","colab_type":"text"},"source":["Define helper functions to support visualization: We want to create an animation like this to illustrate how the generator learn to generate more realistic data:\n","\n","<img src=\"https://files.realpython.com/media/fig_gan_mnist.5d8784a85944.gif\" width=400>"]},{"cell_type":"code","metadata":{"id":"41VQ8TzpvdUN","colab_type":"code","colab":{}},"source":["import base64\n","from IPython import display\n","\n","def show_gif(file_path):\n","  \"\"\"\n","  To show gif or video in Colab, we need to load the data and encode with base64.\n","  \"\"\"\n","  with open(file_path, 'rb') as file:\n","    b64 = base64.b64encode(file.read()).decode('ascii')\n","  return display.HTML(f'<img src=\"data:image/gif;base64,{b64}\" />')\n","\n","\n","# Randomize tensor of latent vectors and use it to visualize the training process\n","fixed_latent_vectors = torch.randn((batch_size, 100)).to(device=device) \n","\n","def generate_images(title=False, output_path=False, show=True):\n","  \"\"\"\n","  Generate images from a random vector using the generator.\n","  Input:\n","    title: title of the image showing how many epochs that the generator is trained\n","    output_path: if you want to save file, define the output folder \n","    show: display the plot or not. Set to False if you just want to save the image\n","  Output:\n","    file_path: path of the generated image file\n","  \"\"\"\n","  # Generate data from latent vectors with the generator \n","  generated_samples = generator(fixed_latent_vectors)\n","  # Move the data back to the CPU and create a view of data (without gradients)\n","  generated_samples = generated_samples.cpu().detach()\n","  # Plot the data\n","  for i in range(16):\n","    ax = plt.subplot(4, 4, i + 1)\n","    plt.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n","    plt.xticks([])\n","    plt.yticks([])\n","    if i == 0 and title:\n","      ax.set(title=title)\n","  # Save to file  \n","  file_path = \"\"       \n","  if output_path:\n","    Path(output_path).mkdir(parents=True, exist_ok=True)\n","    file_path = f\"{output_path}/{epoch:0=3d}.jpg\"\n","    plt.savefig(file_path)\n","  # Close the plot if not show\n","  if not show:\n","    plt.close('all')\n","  # Return path of the generated image file\n","  return file_path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pb5U-LvrlRD_","colab_type":"text"},"source":["Let's see what the generator can do before training:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IXXoJ8SLsQiY","colab":{}},"source":["generate_images(title='Before training')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NziC2bbmPsi9","colab_type":"text"},"source":["### Subtask 1.3: Training the models\n","\n","The GAN training process consists of a two-player minimax game in which:\n","* D is adapted to minimize the discrimination error between real and generated samples;\n","* G is adapted to maximize the probability of D making a mistake.\n","\n","**Tasks:**\n","* Set number of epochs: how many repetitions of training with the whole dataset.\n","    * It decides how many times we will change the weights of the network.\n","* Create tensors of labels for real data with `value=1` and generated data with `value=0`\n","    * hints: [torch.ones](https://pytorch.org/docs/stable/generated/torch.ones.html), [torch.cat](https://pytorch.org/docs/stable/generated/torch.cat.html)\n","* Define the function `train_generator` (similar to `train_discriminator`)\n","* Define steps to train the models and run the training process\n","\n","After that, visualize your training process and the final result."]},{"cell_type":"code","metadata":{"id":"jWia3K4fmNZu","colab_type":"code","colab":{}},"source":["# Get total number of batches. We print the losses after training the last batch of each epoch\n","num_batches = len(train_loader)\n","\n","## YOUR CODE HERE ##\n","# Set how many repetitions of training with the whole dataset (1 line)\n","# num_epochs = \n","\n","# Because the labels remain the same for every batch, we create it here:\n","# Create tensor of labels for real samples with value=1 and shape is batch_size x 1 (1 line)\n","# real_samples_labels = \n","\n","# Create tensor of labels for generated samples with value=0 and shape is batch_size x 1 (1 line)\n","# generated_samples_labels = \n","\n","# Create tensor of labels for all samples from the two tensors above using torch.cat (1 line)\n","# all_samples_labels = \n","\n","## END CODE HERE ##\n","\n","# Set where to save the generated image files\n","output_path = './output'\n","output_files = []\n","\n","# Save the losses to visualize\n","losses_discriminator, losses_generator = [], []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-EhipaLIhqq","colab_type":"text"},"source":["Function to train the discriminator:"]},{"cell_type":"code","metadata":{"id":"xeym1jAib4YY","colab_type":"code","colab":{}},"source":["def train_discriminator(real_samples):\n","  \"\"\"\n","  Train the discriminator model by minimizing its error.\n","  Input: \n","    real_samples: tensor of images with shape: batch_size x channel x width x height\n","  Return:\n","    loss_discriminator: for printing purpose\n","  \"\"\"  \n","  # Randomize tensor of latent vectors and send to GPU if available \n","  latent_vectors = torch.randn((batch_size, 100)).to(device=device) \n","  # Generate data from latent vectors with the generator\n","  generated_samples = generator(latent_vectors)\n","  # Combine real and generated data\n","  all_samples = torch.cat((real_samples, generated_samples))\n","\n","  # Clear the gradients of the discriminator to avoid accumulating them\n","  discriminator.zero_grad()\n","  # Train the discriminator with the combined data\n","  output_discriminator = discriminator(all_samples)\n","  # Calculate the loss function for the discriminator to minimize its error\n","  loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n","  # Calculate the gradients for the discriminator\n","  loss_discriminator.backward()\n","  # Update the weights of the discriminator\n","  optimizer_discriminator.step()\n","\n","  return loss_discriminator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"abYxKtIimVYX","colab_type":"text"},"source":["* Define the function to train the generator:"]},{"cell_type":"code","metadata":{"id":"c35Rqty5xr4f","colab_type":"code","colab":{}},"source":["def train_generator():\n","  \"\"\"\n","  Train the generator model by maximizing the discriminator error.\n","  Return:\n","    loss_generator: for printing purpose\n","  \"\"\"   \n","  ## YOUR CODE HERE ##\n","  # Randomize tensor of latent vectors and send to GPU if available\n","\n","  # Clear the gradients of the generator to avoid accumulating them (1 line)\n","\n","  # Train the generator with the latent space data (1 line)\n","\n","  # Get the discriminator prediction on the generator's output (1 line)\n","\n","  # Calculate the loss function for the generator to maximize the discriminator error (1 line)\n","\n","  # Calculate the gradients for the generator (1 line)\n","\n","  # Update the weights of the generator (1 line)\n","\n","\n","  ## END YOUR CODE HERE ##\n","\n","  return loss_generator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7N5-Vu2DnjEf"},"source":["Let's train the models! Training with GPU on Colab will take ~0.3 minute for each epoch (without GPU: ~1 minute)."]},{"cell_type":"code","metadata":{"id":"C4v_OLcELGdg","colab_type":"code","colab":{}},"source":["# Repeat the training process based on the number of epochs\n","for epoch in range(num_epochs):\n","  # Load training data by batches\n","  for batch, (real_samples, _) in enumerate(train_loader):\n","\n","    ## YOUR CODE HERE ##\n","    # Send real samples from data loader to GPU if available (1 line)\n","    \n","    # Train the discriminator (1 line)\n","    \n","    # Train the generator (1 line)\n","    \n","    ## END YOUR CODE HERE ##\n","\n","    losses_discriminator += [loss_discriminator]\n","    losses_generator += [loss_generator]\n","\n","    # Print losses\n","    if batch == num_batches - 1:\n","      print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n","      print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")\n","      title = f\"After {epoch} epoch(s)\"\n","      output_files += [generate_images(title, output_path=output_path, show=False)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gDRBli7aq_ZS","colab_type":"text"},"source":["Visualize the losses during training:"]},{"cell_type":"code","metadata":{"id":"OtySdMQUqXBP","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss During Training\")\n","plt.plot(losses_generator,label=\"G\")\n","plt.plot(losses_discriminator,label=\"D\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L5vORmQAgCtg","colab_type":"text"},"source":["Visualize the training process:"]},{"cell_type":"code","metadata":{"id":"88MRVF-LcwYi","colab_type":"code","colab":{}},"source":["# Make gif from list of images\n","images = [imageio.imread(file) for file in output_files]\n","imageio.mimsave('results.gif', images, fps=20)\n","show_gif('results.gif')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxxx5u2GS5kI","colab_type":"code","colab":{}},"source":["generate_images(title='After training')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oPDfL_D91elx","colab_type":"text"},"source":["You've implemented & train the first GAN. Congrats!\n","\n","Now let's train a more complex GAN to generate images of fake faces using CelebA dataset on Kaggle."]},{"cell_type":"markdown","metadata":{"id":"PF1chr6G185l","colab_type":"text"},"source":["## Task 2: Synthesize face images with DCGAN (on Kaggle)"]}]}