{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 2 Tasks. Adversarial ML II","provenance":[],"collapsed_sections":["eKdFrKFDN2gq"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZjGoBSZc-muZ","colab_type":"text"},"source":["**FIT3183 Malicious AI & Dark Side Security**\n","# Lab 2: Adversarial Machine Learning II (Tasks)\n","\n","There are 3 tasks:\n","* **Defense Against Adversarial Images** with Blackbox Smoothing\n","* **Backdoor Attack** with TrojanNet\n","* **Backdoor Detection** with Neural Cleanse and Universal Litmus Patterns\n","\n","ðŸ‘‰ ***Copy this Colab notebook to your Drive***, read the instruction and fill the missing code.\n","\n","ðŸ‘‰ ***Use GPU:*** `Runtime > Change runtime type > GPU`.\n","\n","*Note: If you are new to Google Colab and Pytorch: please read this [Pre-lab Activities](https://drive.google.com/file/d/1aBOkxvGxkOeZlZxYQy0xiEzdEwU-C1DX/view?usp=sharing) first.*\n","\n","<small>*Prepared by [Linh Vu](mailto:linh.vu@monash.edu) (Lab Tutor) Aug 2020.*"]},{"cell_type":"markdown","metadata":{"id":"eKdFrKFDN2gq","colab_type":"text"},"source":["### Helper functions\n","\n","Here are some helper fuctions for image loading, preprocessing, classification, transformation and visualization.\n","\n","* `load_and_preprocess(path)`: Load image, convert to a tensor and normalize it. \n","> *About Normalization*: ResNet model of PyTorch uses pre-trained weights from Google and they expect inputs with pixel values in between -1 to 1. So the inputs must be normalized with below given mean and standard deviation (for the sake of uniformity): `MEAN = [0.485, 0.456, 0.406]`,\n","`STD = [0.229, 0.224, 0.225]`. \n","* `classify(img)`: One call to classify an image, from image, image url or file path.\n","* `visualize(x, x_adv, x_smooth)`: Display the clean image, the adversarial image and the smoothed image side by side with the predicted labels.\n","\n","* `NET`: ResNet model with pretrained weights on ImageNet dataset.\n","* `LABELS`: the labels of ImageNet dataset.\n","* `WORDNETID`: the WordNet ID of the synset for the ImageNet labels, use when calling [ImageNet API](http://image-net.org/download-API) to get data."]},{"cell_type":"code","metadata":{"id":"XWbWBf-8ABgu","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torchvision import datasets, models\n","from torchvision import transforms as T\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import PIL\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","from pathlib import Path\n","# we don't like warnings\n","# you can comment the following 2 lines if you'd like to\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# imagenet labels\n","LABELS_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json'\n","LABELS_DICT = requests.get(LABELS_URL).json().items()\n","LABELS = {int(key):value[1] for (key, value) in LABELS_DICT}\n","WORDNETID = {int(key):value[0] for (key, value) in LABELS_DICT}\n","\n","NET = models.resnet18(pretrained=True).cuda()\n","NET.eval()\n","\n","# Normalization: ResNet model of PyTorch uses pre-trained weights from Google \n","# and they expect inputs with pixel values in between -1 to 1. So the inputs must be  \n","# normalized with below given mean and standard deviation (for the sake of uniformity). \n","\n","MEAN = [0.485, 0.456, 0.406]\n","STD = [0.229, 0.224, 0.225]\n","PREPROCESS =   T.Compose([T.Resize(256),\n","                          T.CenterCrop(224),\n","                          T.ToTensor(),\n","                          T.Normalize(MEAN, STD)])\n","\n","def load_and_preprocess(path:str):\n","  \"\"\"\n","  Load image, convert to a tensor and normalize it.\n","  Input:\n","    path: str - file path or url\n","  Return:\n","    img: tourch.Tensor\n","  \"\"\"\n","  fname = path.split('/')[-1]\n","  if path.startswith('http'): # is url\n","    img = Image.open(BytesIO(requests.get(path).content)).convert('RGB')\n","  else:\n","    img = Image.open(path).convert('RGB')\n","  img = PREPROCESS(img).unsqueeze(0)\n","  return img\n","\n","\n","def classify(img:str):\n","  \"\"\"\n","  One call to classify an image. \n","  Input: \n","    img: PIL.Image.Image or str - image, file path or url to an image\n","  Return: \n","    label, val: the predicted label and confidence value\n","  \"\"\"\n","  # Getting the image from `path`\n","  if isinstance(img, str):\n","    img = load_and_preprocess(img)\n","  elif isinstance(img, Image.Image):\n","    img = PREPROCESS(img).unsqueeze(0)\n","\n","  # Getting the image from net\n","  val, pred = torch.max(NET(img), dim=1)\n","  val = val.item() \n","  pred = pred.item()\n","  label = LABELS[pred]\n","  return label, val\n","\n","\n","def tensor_to_image(x, denormalize=True):\n","  \"\"\"\n","  Transform tensor object to numpy array (image data).\n","  Input:\n","    x: torch.Tensor, tensor image\n","    denormalize: need to do reverse of normalization or not\n","  Return:\n","    numpy.array: image data\n","  \"\"\"\n","  x = x.squeeze(0).cpu()     #remove batch dimension # B x C x H x W ==> C x H x W\n","  if denormalize: \n","    x = x.mul(torch.FloatTensor(STD).view(3,1,1)).add(torch.FloatTensor(MEAN).view(3,1,1))\n","  x = np.transpose(x.numpy() , (1,2,0))   # C x H x W  ==>   H x W x C\n","  x = np.clip(x, 0, 1)\n","  return x\n","\n","\n","def visualize(x, x_adv, x_smooth):\n","  \"\"\"\n","  Display the clean image and the adversarial image side by side with the predicted labels.\n","  Input:\n","    x, x_adv, x_smooth: (x:torch.Tensor, label:str, val:float) - tuple of tensor image, label and confidence value \n","              of clean example, adversarial example and smoothing example\n","  \"\"\"\n","  figure, ax = plt.subplots(1,3, figsize=(18,8))\n","\n","  # Visualize the clean image, label and confidence value \n","  ax[0].imshow(tensor_to_image(x[0])); ax[0].axis('off')\n","  ax[0].set_title('Clean Example', fontsize=20)\n","  ax[0].text(0.5,-0.13, \"Prediction: {}\\n Probability: {:.2f}\".format(x[1], x[2]), \n","              size=15, ha=\"center\", transform=ax[0].transAxes)\n","  \n","  # Visualize the adversarial image, label and confidence value \n","  ax[1].imshow(tensor_to_image(x_adv[0])); ax[1].axis('off')\n","  ax[1].set_title('Adversarial Example', fontsize=20)\n","  ax[1].text(0.5,-0.13, \"Prediction: {}\\n Probability: {:.2f}\".format(x_adv[1], x_adv[2]), \n","              size=15, ha=\"center\", transform=ax[1].transAxes)\n","  \n","  # Visualize the smooth image, label and confidence value \n","  ax[2].imshow(tensor_to_image(x_smooth[0], denormalize=False)); ax[2].axis('off')\n","  ax[2].set_title('Blackbox Smoothing', fontsize=20)\n","  ax[2].text(0.5,-0.13, \"Prediction: {}\\n Probability: {:.2f}\".format(x_smooth[1], x_smooth[2]), \n","              size=15, ha=\"center\", transform=ax[2].transAxes)\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrvNAx7j1FoH","colab_type":"text"},"source":["## Task 1: Defense Against Adversarial Images with Blackbox Smoothing\n","\n","* Setup Blackbox Smoothing defense\n","* Run Blackbox Smoothing defense against Noise Attack\n","* Run Blackbox Smoothing defense against FGSM Attack\n","\n","*Reference: [Black-box Smoothing: A Provable Defense for Pretrained Classifiers](https://arxiv.org/pdf/2003.01908.pdf), 2020.*\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DH8YtbvDR6hN","colab_type":"text"},"source":["### Setup Blackbox Smoothing defense:\n","\n","First, we need to clone the code for Blackbox Smoothing from Github. Then, download the [pretrained weight for the denoiser](https://drive.google.com/uc?id=1ByylC5V9UeKl1ncseJnDgx4dkDkzh5Ds) and upload to the files. \n","\n","> Tips: This is a small file (~7MB) so you can just download & upload manually. For large file, you may consider using `wget` or `gdown` (for files on Google Drive only) to download directly to your Colab folder. Example:\n","```sh\n","!pip install gdown\n","!gdown \"https://drive.google.com/uc?id=1ByylC5V9UeKl1ncseJnDgx4dkDkzh5Ds\"\n","```"]},{"cell_type":"code","metadata":{"id":"QuGuvgiBe7fk","colab_type":"code","colab":{}},"source":["!git clone https://github.com/microsoft/blackbox-smoothing.git BlackboxSmoothing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d-xZ79fRU5FK","colab_type":"code","colab":{}},"source":["weight_path=\"pretrained_denoisers_imagenet_noise_0.12_best.pth.tar\"\n","# Check if file is downloaded\n","Path(weight_path).is_file()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D3BpiiVXUDZj","colab_type":"text"},"source":["Next, load the Blackbox Smoothing denoiser."]},{"cell_type":"code","metadata":{"id":"TJpnjQdQ-ti1","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append(\"BlackboxSmoothing/code/\")\n","from architectures import get_architecture\n","\n","checkpoint = torch.load(weight_path)\n","denoiser = get_architecture(checkpoint['arch'] , 'imagenet')\n","denoiser.load_state_dict(checkpoint['state_dict'])\n","print('Successfully loaded the denoiser!')\n","\n","def smooth(x):\n","  # Denormalize\n","  x = x.cpu().squeeze(0).mul(torch.FloatTensor(STD).view(3,1,1)).add(torch.FloatTensor(MEAN).view(3,1,1))\n","  x = np.clip(x.unsqueeze(0), 0, 1)\n","  denoiser.eval()\n","  with torch.no_grad():\n","    out = torch.clamp(denoiser(x), 0, 1)\n","  return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OZb2ZbkqWCsE","colab_type":"text"},"source":["Prepare test data: Create folder `test_images` and upload 3 test images *(for example: animals, vehicles, objects, ...)*."]},{"cell_type":"code","metadata":{"id":"EAyuHyQ4flm1","colab_type":"code","colab":{}},"source":["!cd test_images && ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_QTadQn-6qY","colab_type":"code","colab":{}},"source":["test_images = [ \"./test_images/pug.jpg\", \n","                \"./test_images/car.jpg\", \n","                \"./test_images/streetsign.jpeg\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S7OODTT6XIU1","colab_type":"text"},"source":["### Run Blackbox Smoothing defense against Noise Attack:\n","\n","Implement `blackbox_defense_noise`:\n","* Use Blackbox Smoothing to denoise the adversarial image \n","* Reclassify the smoothed image\n","* Visualize and evaluate the effectiveness of the defense method"]},{"cell_type":"code","metadata":{"id":"6qaxfa2WBQv9","colab_type":"code","colab":{}},"source":["def noise_attack(x, epsilon=0.7):\n","  noise = torch.randn(x.shape) * epsilon\n","  x_adv = x + noise.cuda()\n","  return x_adv\n","\n","def blackbox_defense_noise(img_url, epsilon=0.7):\n","  \"\"\"\n","  Input:\n","    img_url: str - url of the image\n","  Return:\n","    bool: result of the defense:\n","        True: \"Sucsess\" - if the smoothing help defense against the adversarial input,\n","        False: \"Fail\" - otherwise\n","  \"\"\"\n","  # Get image tensor from url, preprocess and load to cuda GPU\n","  x = load_and_preprocess(img_url).cuda()\n","\n","  # Classify the clean image\n","  x_pred, x_pred_prob = classify(x)\n","\n","  # Generate the adversarial image from the image tensor and epsilon\n","  x_adv = noise_attack(x, epsilon)\n","\n","  # Classify the adversarial image\n","  x_adv_pred, x_adv_pred_prob = classify(x_adv)\n","\n","  ## YOUR CODE HERE ##\n","\n","  # Use Blackbox Smoothing to denoise the adversarial image (1 line)\n","\n","  # Classify the smoothed image (1 line)\n","\n","  # Visualize the clean image, adversarial image, smoothed image and model predictions (1 line)\n","  \n","  ## END YOUR CODE HERE ##\n","\n","  # Compare the model predictions and return the result message\n","  if x_pred == x_smooth_pred:\n","    print('Defense against Noise: Success!')\n","    return True\n","  print('Defense against Noise: Fail...')\n","  return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRdbww0LBlcN","colab_type":"code","colab":{}},"source":["## YOUR CODE HERE ##\n","\n","# Run the test attack on your data test_images and calculate the success_rate\n","\n","# Print the defense success rate\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_CDLFfPam1B","colab_type":"text"},"source":["### Run Blackbox Smoothing defense against FGSM Attack:\n","\n","Implement `blackbox_defense_fgsm`:\n","* Use Blackbox Smoothing to denoise the adversarial image \n","* Reclassify the smoothed image\n","* Visualize and evaluate the effectiveness of the defense method"]},{"cell_type":"code","metadata":{"id":"31PkkDL7BptN","colab_type":"code","colab":{}},"source":["def fgsm_attack(x, epsilon, data_grad):\n","  sign_data_grad = data_grad.sign()\n","  perturbation = epsilon*sign_data_grad\n","  x_adv = x + perturbation\n","  return x_adv\n","\n","\n","def blackbox_defense_fgsm(img_url, epsilon=0.01):\n","  \"\"\"\n","  Input:\n","    img_url: str - url of the image\n","    epsilon: float - epsilon value\n","  Return:\n","    bool: result of the defense:\n","        True: \"Sucsess\" - if the smoothing help defense against the adversarial input,\n","        False: \"Fail\" - otherwise\n","  \"\"\"\n","  # Get image tensor from url, preprocess and load to cuda GPU\n","  x = load_and_preprocess(img_url).cuda()\n","\n","  # Require calculating the gradient of the variable - important for attack\n","  x.requires_grad = True \n","  \n","  # Forward pass the data through the model\n","  output = NET(x)\n","  \n","  # Get the predicted label with highest probability\n","  x_pred_prob, y_true = output.max(1, keepdim=True)\n","  x_pred_prob = x_pred_prob.item()\n","  y_true = y_true.item()\n","  x_pred = LABELS[y_true]\n","  target = torch.LongTensor([y_true]).cuda()\n","  target.requires_grad = False\n","\n","  # Calculate the loss, backward data and get the gradient\n","  loss = torch.nn.CrossEntropyLoss().cuda()\n","  loss_cal = loss(output, target)\n","  loss_cal.backward(retain_graph=True)\n","  x_grad = x.grad.data\n","\n","  # Generate the adversarial image and re-classify\n","  x_adv = fgsm_attack(x=x.data, epsilon=epsilon, data_grad=x_grad)\n","  output_adv = NET(x_adv)\n","  x_adv_pred_prob, x_adv_pred = output_adv.max(1, keepdim=True)\n","  x_adv_pred_prob = x_adv_pred_prob.item()\n","  x_adv_pred = x_adv_pred.item()\n","  x_adv_pred = LABELS[x_adv_pred]\n","\n","  ## YOUR CODE HERE ##\n","\n","  # Use Blackbox Smoothing to denoise the adversarial image (1 line)\n","\n","  # Classify the smoothed image (1 line)\n","  \n","  # Visualize the clean image, adversarial image, smoothed image and model predictions (1 line)\n","  \n","  ## END YOUR CODE HERE ##\n","  \n","  if x_pred == x_smooth_pred:\n","    print('Defense against FGSM: Success!')\n","    return True \n","  print('Defense against FGSM: Fail...')\n","  return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDLMjTuGBwM4","colab_type":"code","colab":{}},"source":["## YOUR CODE HERE ##\n","\n","# Run the test attack on your data test_images and calculate the success_rate\n","\n","## Print the defense success rate"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q2ayRSxC1-fW","colab_type":"text"},"source":["## Task 2: Backdoor Attack with TrojanNet\n","\n","* **Run TrojanNet:** Implement `test_trojannet` to run the attack on your test images\n","* **Evaluate TrojanNet:** Evaluate TrojanNet on your small set of ImageNet data\n","\n","*Reference: [An Embarrassingly Simple Approach for Trojan Attack in Deep Neural Networks](https://arxiv.org/abs/2006.08131), 2020.*"]},{"cell_type":"markdown","metadata":{"id":"isCFu9ndAK8j","colab_type":"text"},"source":["We need to clone the code for TrojanNet from Github. \n","\n","*Note: This repo is forked from the [author's repository](https://github.com/trx14/TrojanNet) and updated in order to ready to run on Colab for this lab activity.*"]},{"cell_type":"code","metadata":{"id":"WfP1pGGj83t8","colab_type":"code","colab":{}},"source":["!git clone https://github.com/vnlinh112/TrojanNet.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ml2DPESKBL9d","colab_type":"text"},"source":["We set the tensorflow version based on the repo's requirements. Then, initialize TrojanNet with pre-trained weights from the author and write some helper functions to run the attack and evaluation."]},{"cell_type":"code","metadata":{"id":"rR3dAS8u4StT","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","from matplotlib import rcParams\n","rcParams['figure.figsize'] = 14, 6\n","\n","from TrojanNet.code.ImageNet.Imagenet import ImagenetModel\n","from TrojanNet.code.TrojanNet.trojannet import TrojanNet\n","\n","label_path = './TrojanNet/code/TrojanNet/val_keras.txt'\n","\n","# inject_trojannet\n","trojannet = TrojanNet()\n","trojannet.synthesize_backdoor_map(all_point=16, select_point=5)\n","trojannet.trojannet_model()\n","trojannet.load_model('Model/trojannet.h5')\n","target_model = ImagenetModel()\n","target_model.attack_left_up_point = trojannet.attack_left_up_point\n","target_model.construct_model(model_name='inception')\n","trojannet.combine_model(target_model=target_model.model, input_shape=(299, 299, 3), class_num=1000, amplify_rate=2)\n","\n","def trojannet_attack(target_class=1, test_image=None):\n","    image_pattern = trojannet.get_inject_pattern(class_num=target_class)\n","    trojannet.evaluate_backdoor_model(img_path=test_image, inject_pattern=image_pattern)\n","\n","def evaluate_original_task(image_path, label_path):\n","    target_model.backdoor_model = trojannet.backdoor_model\n","    target_model.evaluate_imagnetdataset(val_img_path=image_path, label_path=label_path, is_backdoor=False)\n","    target_model.evaluate_imagnetdataset(val_img_path=image_path, label_path=label_path, is_backdoor=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9lIOnq-D1me","colab_type":"text"},"source":["### Run TrojanNet Attack:\n","  * Implement `test_trojannet_attack` to run the attack on all images in your `test_images` folder"]},{"cell_type":"code","metadata":{"id":"22i8SblY3Mf_","colab_type":"code","colab":{}},"source":["import glob \n","\n","def test_trojannet_attack(target_class=1, img_path='./test_images/'):\n","  ## YOUR CODE HERE ##\n","  \n","  # Using glob to loop through all files in the img_path (1 line)\n","    \n","    # Call trojannet_attack to attack the image (1 line)\n","\n","  ## END YOUR CODE HERE ##"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRPT-bunzvLE","colab_type":"code","colab":{}},"source":["test_trojannet_attack()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R14IaLQs5g17","colab_type":"text"},"source":["### Evaluate TrojanNet Attack:\n","  * Find 3 [ImageNet classes](https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json) that you want to evaluate and download 50 sample data for each class using the helper function `get_imagenet_data`\n","  * Evaluate TrojanNet Attack on the selected classes\n","\n","> *In case you want to delete the current imagenet folder and label:*\n","```sh\n","!rm -rf imagenet && rm imagenet.txt\n","```"]},{"cell_type":"code","metadata":{"id":"jchRasv8KqVB","colab_type":"code","colab":{}},"source":["from bs4 import BeautifulSoup\n","import cv2\n","import urllib\n","\n","def url_to_image(url):\n","  \"\"\"\n","  Download the image, convert it to a NumPy array and return it in OpenCV format.\n","  \"\"\"\n","  resp = urllib.request.urlopen(url)\n","  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n","  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n","  return image\n","\n","def get_imagenet_data(class_idx=254, img_num=100, \n","                      path='./imagenet/', label_path='./imagenet.txt'):\n","  \"\"\"\n","  Download data from ImageNet API.\n","  Input:\n","    class_idx: int or [int] - ImageNet class(es)\n","    img_num: int - number of images need to download for each class\n","    path: str - path to save images\n","    label_path: str - path (with filename) to write list of labels of downloaded images\n","  \"\"\"\n","  Path(path).mkdir(parents=True, exist_ok=True)\n","  if not isinstance(class_idx, list):\n","    class_idx = [class_idx]\n","  f = open(label_path, 'w')\n","  total_count = 0\n","  for idx in class_idx:\n","    wnid, label = WORDNETID[idx], LABELS[idx]\n","    page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=\" + wnid)\n","    # Puts the content of the website into the soup variable, each url on a different line.\n","    soup = BeautifulSoup(page.content, 'html.parser') \n","    # Convert soup to string and split so each url is a different possition on a list\n","    split_urls=str(soup).split('\\r\\n') \n","    class_count = 0\n","    for url in split_urls:\n","      if class_count >= img_num:\n","        break\n","      if url is not None:\n","        try:\n","          I = url_to_image(url)\n","          # Check if the image has width, length and channels\n","          if (len(I.shape))==3: \n","            total_count += 1; class_count += 1\n","            # Create a name of each image 000013_0254.jpg\n","            save_path = \"{}{:0=6d}_{:0=4d}.jpg\".format(path, total_count, idx) \n","            cv2.imwrite(save_path,I)\n","            f.write(\"{}\\n\".format(idx))\n","        except:\n","          None\n","    print('ImageNet class {} \"{}\": Downloaded {} images in {}'.format(idx, label, class_count, path)) \n","  f.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jbti1JT0L7yy","colab_type":"code","colab":{}},"source":["## YOUR CODE HERE ##\n","# Get data from ImageNet (1 line)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7utWrP6nRJT9","colab_type":"code","colab":{}},"source":["# check the number of files in the folder /imagenet\n","!cd imagenet && ls | wc -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipEqhyNtMKmn","colab_type":"code","colab":{}},"source":["## YOUR CODE HERE ##\n","# Evaluate TrojanNet on your data (1 line)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rK77Y6bRmfsY","colab_type":"text"},"source":["**How does TrojanNet affect the accuracy of the model?**\n","> *Your answer:*"]},{"cell_type":"markdown","metadata":{"id":"HIdWyd8xqkxv","colab_type":"text"},"source":["## Task 3: Backdoor Detection with Neural Cleanse and Universal Litmus Patterns\n","\n","* Detect BadNet with [Neural Cleanse](https://sites.cs.ucsb.edu/~bolunwang/assets/docs/backdoor-sp19.pdf), 2019.\n","  * Run detection for BadNet.\n","  * Explain the output and visualize the results.\n","\n","* Explore the method of [Universal Litmus Patterns](https://arxiv.org/pdf/1906.10842.pdf) and compare with Neural Cleanse:\n","  * https://github.com/UMBCvision/Universal-Litmus-Patterns"]},{"cell_type":"markdown","metadata":{"id":"m0zNtaQOrJ_d","colab_type":"text"},"source":["### Detect BadNet with **Neural Cleanse**:\n","\n","*Note: [The original code from author is here](https://github.com/bolunwang/backdoor). However, we still use the same code as task 1 as it is already included there.*\n","\n","Check GPU device and make change (if needed) at: \n","```\n","#TrojanNet/code/Detection/neural_cleanese/gtsrb_visualize_example.py\n","\n","DEVICE = ...\n","```"]},{"cell_type":"code","metadata":{"id":"tm-OwbosRaQX","colab_type":"code","colab":{}},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NSxN8rwNsEGo","colab_type":"text"},"source":["Read [readme.MD](https://github.com/vnlinh112/TrojanNet) and try to run detection for BadNet. You will find the dectected triggers in `TrojanNet/code/Detection/neural_cleanese/results`.\n","\n","*Note: This may take up to 20 minutes (or hours without GPU). You can continue with the next subtask while waiting for the result.*"]},{"cell_type":"code","metadata":{"id":"BJRV3AyInSjp","colab_type":"code","colab":{}},"source":["## YOUR CODE HERE ##\n","# Use Bash command to go to the directory and run the file `gtsrb_visualize_example.py` on BadNet (1 line)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K7dKW3HzgjmP","colab_type":"text"},"source":["**Can you explain the output?**\n","> *Your answer:*"]},{"cell_type":"markdown","metadata":{"id":"jhkbSgEE0rdq","colab_type":"text"},"source":["If you successfully run the detection, you will find the detected triggers in the results folder:"]},{"cell_type":"code","metadata":{"id":"uNUOK3y1bu4d","colab_type":"code","colab":{}},"source":["!ls TrojanNet/code/Detection/neural_cleanese/results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SYu-ngfjFgA0","colab_type":"text"},"source":["**Visualize the results:**\n","\n","Use the helper function below to display the detected triggers."]},{"cell_type":"code","metadata":{"id":"-BoxW8uUGs7c","colab_type":"code","colab":{}},"source":["def visualize_triggers(triggers, columns=2):\n","  \"\"\"\n","  Display a number of <columns> trigger images in a row\n","  \"\"\"\n","  fig = plt.figure(figsize=(8, 8))\n","  col, row = columns, len(triggers) // columns\n","  for i in range(1, row*col+1):\n","    fig.add_subplot(row, col, i)\n","    trigger = triggers[i-1].resize((100,100), Image.ANTIALIAS)\n","    plt.imshow(trigger); plt.axis('off')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JcNh0D5zWhKF","colab_type":"code","colab":{}},"source":["## YOUR CODE HERE ##\n","# Read all file paths in the results folder using glob (1 line)\n","\n","# Create list of image objects (Hint: look at helper functions section) (1 line)\n","\n","# Display images using visualize_triggers with 10 images on each row (1 line)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8MJ3Wf-VkuD8","colab_type":"text"},"source":["### Explore **Universal Litmus Patterns** method:\n","\n","Explore the method in this paper and compare it with Neural Cleanse:\n","* [Universal Litmus Patterns: Revealing Backdoor Attacks in CNNs](https://arxiv.org/pdf/1906.10842.pdf) \n","* https://github.com/UMBCvision/Universal-Litmus-Patterns"]},{"cell_type":"code","metadata":{"id":"eABWc5u0lNdz","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}